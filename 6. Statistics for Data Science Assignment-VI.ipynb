{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ab615df-3ed3-41e4-a749-ddb4209070bc",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/57321948/196933065-4b16c235-f3b9-4391-9cfe-4affcec87c35.png)\n",
    "\n",
    "# Name: Mohammad Wasiq\n",
    "\n",
    "## E-mail: `mohammadwasiq0786@gmail.com`\n",
    "\n",
    "## Statistics for Data Science Assignment - VI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e0d534-8ee2-4e43-8a9e-a9161633c2a5",
   "metadata": {},
   "source": [
    "**`Q1.`** **What is a Cumulative Distribution Function, and how does it work ?**\n",
    "\n",
    "**`Ans`** \n",
    "\n",
    "A **cumulative distribution function (CDF)** is a function that describes the probability that a random variable takes a value less than or equal to a given value. In other words, it is the cumulative sum of probabilities for all values less than or equal to a certain point.\n",
    "\n",
    "The CDF is represented by a graph, where the x-axis represents the possible values of the random variable and the y-axis represents the probability that the value is less than or equal to that point. The graph starts at zero on the left-hand side, and the area under the curve is equal to 1, meaning that the sum of all probabilities for all possible outcomes is equal to 1.\n",
    "\n",
    "The CDF is useful because it allows us to calculate the probability of a range of values for the random variable, rather than just a single value. We can also use the CDF to calculate other statistical measures, such as the median, quartiles, and percentiles of the distribution.\n",
    "\n",
    "To find the probability of a range of values, we subtract the value of the CDF at the lower bound of the range from the value of the CDF at the upper bound of the range. For example, to find the probability that a random variable falls between a and b, we subtract the value of the CDF at a from the value of the CDF at b.\n",
    "\n",
    "There are many different types of probability distributions, and each has a unique CDF that describes the probability distribution. Some common examples include the normal distribution, the exponential distribution, and the Poisson distribution, among others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf34c39-8546-4658-a7af-af3fa2823030",
   "metadata": {},
   "source": [
    "**`Q2.`** **When should we use a t-test vs a z-test ?**\n",
    "\n",
    "**`Ans`** \n",
    "\n",
    "A t-test and a z-test are both statistical tests used to test hypotheses about the mean of a population, but they are used in different situations.\n",
    "\n",
    "A **z-test** is used when the population standard deviation is known, or when the sample size is large (typically greater than 30) and the population standard deviation is assumed to be equal to the sample standard deviation. The z-test is appropriate when the sample size is large enough to assume that the sample mean is normally distributed.\n",
    "\n",
    "A **t-test** is used when the population standard deviation is unknown, and must be estimated from the sample data. The t-test is also used when the sample size is small (typically less than 30). The t-test is appropriate when the sample size is small, and the sample mean is not normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0347cbf6-f554-415d-b4fd-2e3e29127a90",
   "metadata": {},
   "source": [
    "**`Q3.`** **How do we examine two category characteristics ?**\n",
    "\n",
    "**`Ans`** \n",
    "\n",
    "To examine two category characteristics in statistics, we typically use a chi-squared test. This test is used to determine if there is a significant association between two categorical variables.\n",
    "\n",
    "The basic idea behind the chi-squared test is to compare the observed frequencies of each category to the expected frequencies if the two variables were independent. The expected frequencies are calculated assuming that there is no relationship between the two variables. If the observed frequencies are significantly different from the expected frequencies, then we reject the null hypothesis that the two variables are independent and conclude that there is a significant association between them.\n",
    "\n",
    "The steps involved in conducting a chi-squared test are:\n",
    "\n",
    "1. Formulate the null hypothesis and alternative hypothesis\n",
    "\n",
    "* The null hypothesis states that there is no significant association between the two variables\n",
    "* The alternative hypothesis states that there is a significant association between the two variables\n",
    "\n",
    "2. Collect the data and create a contingency table\n",
    "\n",
    "* A contingency table shows the frequencies of each category for each variable\n",
    "\n",
    "3. Calculate the expected frequencies\n",
    "\n",
    "* Calculate the expected frequencies assuming that the two variables are independent\n",
    "\n",
    "4. Calculate the chi-squared statistic\n",
    "\n",
    "* The chi-squared statistic is calculated by summing the squared differences between the observed and expected frequencies\n",
    "\n",
    "5. Determine the degrees of freedom\n",
    "\n",
    "* The degrees of freedom are calculated as (number of rows - 1) x (number of columns - 1)\n",
    "\n",
    "6. Calculate the p-value\n",
    "\n",
    "* The p-value is calculated using a chi-squared distribution table or a statistical software package\n",
    "\n",
    "7. Compare the p-value to the significance level\n",
    "\n",
    "* If the p-value is less than the significance level (usually 0.05), we reject the null hypothesis and conclude that there is a significant association between the two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df608a02-0507-4de1-83d9-d9db8bff27da",
   "metadata": {},
   "source": [
    "**`Q4.`** **Explain the concept of Chebyshev's Inequality.**\n",
    "\n",
    "**`Ans`** \n",
    "\n",
    "**Chebyshev's inequality** is a theorem in probability theory that provides an upper bound on the probability that a random variable deviates from its mean by more than a certain amount.\n",
    "\n",
    "Specifically, Chebyshev's inequality states that for any random variable X with finite mean μ and finite variance σ^2, the probability that X deviates from its mean by more than k standard deviations is at most 1/k^2, for any positive number k greater than 1. Mathematically, we can express this as:\n",
    "\n",
    "$$P(|X- \\mu| \\ge k \\sigma) \\le \\frac{1}{k^2}$$\n",
    "\n",
    "This means that no matter what the distribution of the random variable $X$ is, at least $1 - 1/k^2$ of the values of $X$ will be within k standard deviations of the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44514377-dd71-4751-993d-8d6e97305372",
   "metadata": {},
   "source": [
    "**`Q5.`** **Explain the concept of Pareto Distribution**\n",
    "\n",
    "**`Ans`** \n",
    "\n",
    "The Pareto distribution is a type of probability distribution that is often used in economics, finance, and other fields to model the distribution of wealth, income, and other quantities that exhibit power-law behavior.\n",
    "\n",
    "The Pareto distribution is characterized by a single parameter, α, known as the shape parameter or Pareto index. The probability density function of the Pareto distribution is given by:\n",
    "\n",
    "$$f(x; \\alpha, x_m) = \\frac{\\alpha x_\\mathrm{m}^\\alpha}{x^{\\alpha+1}}\n",
    "$$\n",
    "\n",
    "where $x$ is the random variable, $x_m$ is the minimum possible value of $x$, and $\\alpha$ is the Pareto index.\n",
    "\n",
    "The Pareto distribution has a number of interesting properties. One of the most important is that it exhibits a heavy tail, meaning that it assigns a non-zero probability to extreme events that are much larger than the typical values. This heavy-tailed behavior arises because the Pareto distribution has a power-law decay in the tail, which means that the probability of large values decreases very slowly, as a power-law function.\n",
    "\n",
    "Another important property of the Pareto distribution is that it is scale-invariant, meaning that the distribution is the same regardless of the scale at which it is measured. In other words, if we multiply all values of x by a constant factor, the shape of the distribution remains the same.\n",
    "\n",
    "The Pareto distribution has a number of applications in practice. One of the most well-known is in modeling the distribution of wealth and income, where it is often used to describe the fact that a small number of individuals or households control a large share of the total wealth or income. The Pareto distribution is also used in insurance, where it can be used to model the distribution of losses from rare events, such as natural disasters or large-scale accidents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
